{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikMik1011/petnica_csgo_ai_project/blob/master/PROJEKAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXknHxuy71Rg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "\n",
        "!pip install python-telegram-bot\n",
        "\n",
        "import telegram\n",
        "telegrambot = telegram.Bot(\"5458378014:AAHbuC2qcGiUEqD02i6uWVtuE8y0xP_CzEg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def norm(d):\n",
        "    arr = d.copy()\n",
        "    for i in range(d.shape[1]): \n",
        "      for j in range(d.shape[0]):\n",
        "        arr[j][i] = d[j][i] - d[0][i]\n",
        "    return arr\n",
        "\n",
        "def minmax(d):\n",
        "    arr = d.copy()\n",
        "    for f in range(d.shape[2]):\n",
        "      xmax = d[:,:,f].max()\n",
        "      xmin = d[:,:,f].min() \n",
        "      for i in range(d.shape[0]):\n",
        "        for j in range(d.shape[1]):\n",
        "          x = arr[i][j][f]\n",
        "          arr[i][j][f] = (x - xmin) / (xmax - xmin)\n",
        "    return arr"
      ],
      "metadata": {
        "id": "6EBfoxzNtlmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dara8vsIVP9d"
      },
      "outputs": [],
      "source": [
        "X = np.load('/content/drive/MyDrive/PROJEKAT DATASET/normX.npy')\n",
        "Y = np.load('/content/drive/MyDrive/PROJEKAT DATASET/Y.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = minmax(X)"
      ],
      "metadata": {
        "id": "ZeyucryoPZhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/PROJEKAT DATASET/normX.npy', X)"
      ],
      "metadata": {
        "id": "-7NDpbWuP2Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVLaujDUVsR3"
      },
      "outputs": [],
      "source": [
        "legitX, cheatX = np.split(X, 2)\n",
        "legitY, cheatY = np.split(Y, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOk42pfWXcUW"
      },
      "outputs": [],
      "source": [
        "ltX, leX, ltY, leY = train_test_split(legitX, legitY, test_size=0.20)\n",
        "ctX, ceX, ctY, ceY = train_test_split(cheatX, cheatY, test_size=0.20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnzw08F_cjGw"
      },
      "outputs": [],
      "source": [
        "tX = np.concatenate((ltX, ctX))\n",
        "eX = np.concatenate((leX, ceX))\n",
        "tY = np.concatenate((ltY, ctY))\n",
        "eY = np.concatenate((leY, ceY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9wcEPCFZ5Ke"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "zeror = DummyClassifier()\n",
        "\n",
        "zeror.fit(tX, tY)\n",
        "zeror.score(eX, eY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scJKgdwy_Ju6"
      },
      "outputs": [],
      "source": [
        "def oner(normalize = False):\n",
        "\n",
        "    accs = []\n",
        "  for br in range(tX.shape[2]):\n",
        "    arX = tX[:,:,br]\n",
        "    arY = np.repeat(tY, arX.shape[1])\n",
        "    if (normalize):\n",
        "      arX = norm(arX)\n",
        "    arX = np.reshape(arX, arX.shape[0] * arX.shape[1])\n",
        "    unique, unique_counts = np.unique(arX, return_counts = True)\n",
        "\n",
        "    ar1 = {}\n",
        "    ar0 = {}\n",
        "\n",
        "    for i in range(len(arX)):\n",
        "      if (arY[i] == 1):\n",
        "        try:\n",
        "          ar1[arX[i]] += 1\n",
        "        except:\n",
        "          ar1[arX[i]] = 1\n",
        "      else:\n",
        "          try:\n",
        "            ar0[arX[i]] += 1\n",
        "          except:\n",
        "            ar0[arX[i]] = 1\n",
        "\n",
        "    freq = []\n",
        "\n",
        "    for i in unique:\n",
        "      if (not ar1.get(i)):\n",
        "        freq.append(ar0[i])\n",
        "      elif (not ar0.get(i)):\n",
        "        freq.append(ar1[i])\n",
        "      else:\n",
        "        freq.append(max(ar1[i], ar0[i]))\n",
        "\n",
        "    accs.append(sum(freq) / len(arX))\n",
        "\n",
        "  return accs\n",
        "\n",
        "print(oner())\n",
        "print(oner(normalize = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NT4FVB4usIsQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def custom_f1(y_true, y_pred):    \n",
        "    def recall_m(y_true, y_pred):\n",
        "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        \n",
        "        recall = TP / (Positives+K.epsilon())    \n",
        "        return recall \n",
        "    \n",
        "    \n",
        "    def precision_m(y_true, y_pred):\n",
        "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    \n",
        "        precision = TP / (Pred_Positives+K.epsilon())\n",
        "        return precision \n",
        "    \n",
        "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
        "    \n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh3j_ByfwrGI"
      },
      "outputs": [],
      "source": [
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    \n",
        "    def on_train_begin(self, logs=None):\n",
        "        telegrambot.send_message(text=f\"Fit started\", chat_id=1163033817)\n",
        "      \n",
        "    def on_train_end(self, logs=None):\n",
        "        telegrambot.send_message(text=f\"Fit ended\", chat_id=1163033817)\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      epoch += 1\n",
        "      telegrambot.send_message(text=f\"Epoch {epoch} ended \\nValidation accuracy: {logs['val_binary_accuracy']} \\nValidation F1-score: {logs['val_custom_f1']} \\nValidation loss: {logs['val_loss']}\", chat_id=1163033817)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tojKTbb_xnS8"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(192, 5)))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=keras.losses.BinaryFocalCrossentropy(),\n",
        "              metrics=[keras.metrics.BinaryAccuracy(),\n",
        "                       custom_f1,\n",
        "                       keras.metrics.FalseNegatives(),\n",
        "                       keras.metrics.FalsePositives()\n",
        "                       ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68L18WE2_3ue"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/MODELS/LSTM_2022-08-15_19:56', custom_objects={\"custom_f1\":custom_f1})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ntX = norm(tX)\n",
        "neX = norm(eX)"
      ],
      "metadata": {
        "id": "lbHih2EvoaOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rtY = tY.reshape((-1,1))\n",
        "reY = eY.reshape((-1, 1))"
      ],
      "metadata": {
        "id": "uXRNeBLgq2T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN0_Kx7K-gh4"
      },
      "outputs": [],
      "source": [
        "model.summary()\n",
        "model.fit(tX, tY, batch_size = 25, epochs = 30, validation_data = (eX, eY), shuffle = True, use_multiprocessing = True, verbose = 1, callbacks=[CustomCallback()])\n",
        "model.save(\"/content/drive/MyDrive/MODELS/LSTM_\" + datetime.now().strftime(\"%Y-%m-%d_%H:%M\"))\n",
        "telegrambot.send_message(text=f\"Model saved\", chat_id=1163033817)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix#\n",
        "\n",
        "predY = model.predict(eX)\n",
        "\n",
        "confMatr = confusion_matrix(eY, np.round(predY, decimals = 0) , normalize='pred')\n",
        "print(confMatr)"
      ],
      "metadata": {
        "id": "LMvT6mTpBpTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min(eX[:,:,3].reshape(-1))"
      ],
      "metadata": {
        "id": "EmAS6IwRQKQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "oxrsxNWRGdlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PROJEKAT.ipynb",
      "provenance": [],
      "mount_file_id": "1T4xr40jdVDbimFijGknWh9QthfejwHUm",
      "authorship_tag": "ABX9TyN0Js9L0xfc3K6zhE/ZunQ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}